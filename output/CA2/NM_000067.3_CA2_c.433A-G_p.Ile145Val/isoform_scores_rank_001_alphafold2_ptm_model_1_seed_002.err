
WARNING: You are welcome to use the default MSA server, however keep in mind that it's a
limited shared resource only capable of processing a few thousand MSAs per day. Please
submit jobs only from a single IP address. We reserve the right to limit access to the
server case-by-case when usage exceeds fair use. If you require more MSAs: You can 
precompute all MSAs with `colabfold_search` or host your own API and pass it to `--host-url`

  0%|          | 0/150 [elapsed: 00:00 remaining: ?]SUBMIT:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]COMPLETE:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]COMPLETE: 100%|██████████| 150/150 [elapsed: 00:00 remaining: 00:00]COMPLETE: 100%|██████████| 150/150 [elapsed: 00:02 remaining: 00:00]
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1728091612.947625    2270 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node
Your kernel may have been built without NUMA support.
Traceback (most recent call last):
  File "/mnt/c/Users/lahat/colabfold/localcolabfold/colabfold-conda/bin/colabfold_batch", line 8, in <module>
    sys.exit(main())
  File "/mnt/c/Users/lahat/colabfold/localcolabfold/colabfold-conda/lib/python3.10/site-packages/colabfold/batch.py", line 2046, in main
    run(
  File "/mnt/c/Users/lahat/colabfold/localcolabfold/colabfold-conda/lib/python3.10/site-packages/colabfold/batch.py", line 1583, in run
    results = predict_structure(
  File "/mnt/c/Users/lahat/colabfold/localcolabfold/colabfold-conda/lib/python3.10/site-packages/colabfold/batch.py", line 426, in predict_structure
    model_runner.predict(input_features,
  File "/mnt/c/Users/lahat/colabfold/localcolabfold/colabfold-conda/lib/python3.10/site-packages/alphafold/model/model.py", line 185, in predict
    result, prev = run(sub_key, sub_feat, prev)
  File "/mnt/c/Users/lahat/colabfold/localcolabfold/colabfold-conda/lib/python3.10/site-packages/alphafold/model/model.py", line 165, in run
    result = _jnp_to_np(self.apply(self.params, key, {**feat, "prev":prev}))
KeyboardInterrupt
